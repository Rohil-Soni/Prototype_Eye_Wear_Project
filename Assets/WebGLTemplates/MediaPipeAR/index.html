<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR Face Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0"></script>
    <script src="%UNITY_WEBGL_LOADER_URL%"></script>
</head>
<body style="margin:0;">
    <video id="video" autoplay playsinline style="position:fixed;top:0;left:0;width:100vw;height:100vh;object-fit:cover;z-index:-1;"></video>
    <canvas id="unity-canvas" style="position:fixed;top:0;left:0;width:100vw;height:100vh;"></canvas>
    
    <script>
        // MediaPipe Face Landmarker
        const { FaceLandmarker, FilesetResolver } = window;
        let faceLandmarker;
        
        async function createFaceLandmarker() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: `https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/face_landmarker.task`
                },
                outputFaceBlendshapes: true,
                outputFacialTransformationMatrixes: true,
                numFaces: 1
            });
        }
        
        // Camera setup
        async function startCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'user', width: 1280, height: 720 } 
            });
            document.getElementById('video').srcObject = stream;
            
            await createFaceLandmarker();
            detectFaces();
        }
        
        function detectFaces() {
            const video = document.getElementById('video');
            if (!faceLandmarker || video.readyState !== 4) {
                requestAnimationFrame(detectFaces);
                return;
            }
            
            const results = faceLandmarker.detectForVideo(video, performance.now());
            
            if (results.faceLandmarks && results.faceLandmarks[0]) {
                const landmarks = results.faceLandmarks[0];
                const noseBridge = landmarks[1]; // Key landmark for glasses
                
                // Send to Unity
                if (window.unityInstance) {
                    window.unityInstance.SendMessage('FaceTrackerBridge', 'OnFaceData', 
                        JSON.stringify({ noseX: noseBridge.x, noseY: noseBridge.y }));
                }
            }
            
            requestAnimationFrame(detectFaces);
        }
        
        // Unity WebGL
        createUnityInstance(document.getElementById('unity-canvas'), {
            dataUrl: "%UNITY_WEBGL_DATA_URL%",
            frameworkUrl: "%UNITY_WEBGL_FRAMEWORK_URL%",
            codeUrl: "%UNITY_WEBGL_CODE_URL%",
        }, (progress) => {}).then((unityInstance) => {
            window.unityInstance = unityInstance;
        });
        
        startCamera();
    </script>
</body>
</html>
